{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\icech\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: generator 'make_lines2' raised StopIteration\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Mecab_func import*\n",
    "from collections import Counter\n",
    "\n",
    "#読点以下のMeCabファイルから、4語以下に成型して出力する関数\n",
    "def Output_matsubi_BoWList(write_file,mecab_file):\n",
    "    copus=[]\n",
    "    #語数カウンター\n",
    "    word=\"\"\n",
    "    for morphemes in make_lines2(mecab_file):\n",
    "\n",
    "        if len(morphemes)>=5:\n",
    "            copus.append(morphemes[-5]+morphemes[-4]+morphemes[-3]+morphemes[-2])\n",
    "        elif len(morphemes)>=4:\n",
    "            copus.append(morphemes[-4]+morphemes[-3]+morphemes[-2])\n",
    "        elif len(morphemes)>=3:\n",
    "            copus.append(morphemes[-3]+morphemes[-2])\n",
    "        elif len(morphemes)>=2:\n",
    "            copus.append(morphemes[-2])\n",
    "    word=''.join(str(copus))\n",
    "#     copus_unique=sorted(set(copus),key=copus.index)\n",
    "#     word=' '.join(copus_unique)\n",
    "    return word      \n",
    "\n",
    "#Matubi2を選択➡34対29で計算\n",
    "#Matubiを選択➡28対28\n",
    "\n",
    "#docsに教師データ、labelsにラベルを代入する。\n",
    "docs2=[]\n",
    "labels2=[]\n",
    "path_list2=glob.glob(r'C:\\Users\\icech\\Desktop\\share\\Lab\\2018_07_04\\Docments\\New_yato\\Matubi/*.txt')\n",
    "for i,path in enumerate(path_list2):\n",
    "    docs2.append(Output_matsubi_BoWList('{}_fixed_new_matubi.txt'.format(i),'{}.mecab'.format(path)))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "docs3=[]\n",
    "labels3=[]\n",
    "path_list3=glob.glob(r'C:\\Users\\icech\\Desktop\\share\\Lab\\2018_07_04\\Docments\\Old_yato\\Matubi/*.txt')\n",
    "for i,path in enumerate(path_list3):\n",
    "    docs3.append(Output_matsubi_BoWList('{}_fixed_new_matubi.txt'.format(i),'{}.mecab'.format(path)))\n",
    "    \n",
    "\n",
    "labels3=np.ones(len(path_list3))\n",
    "labels2=np.zeros(len(path_list2))\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2018_07_28　新しい効果検証方法\n",
    "#入れ子式➡普通の検証方法\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#入力データとラベルを結合する\n",
    "labels=np.hstack((labels2,labels3))\n",
    "docs=np.array(docs2+docs3)\n",
    "print(len(docs))\n",
    "print(len(labels))\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(X, labels, test_size=0.2, random_state=0)\n",
    "\n",
    "models_name = [\"SVM\", \"決定木\", \"ランダムフォレスト\",\"ナイーブベイズ\"]\n",
    "models = [SVC(), DecisionTreeClassifier(), RandomForestClassifier(),MultinomialNB()]\n",
    "\n",
    "for name, model, param in zip(models_name, models, params):\n",
    "    clf = model\n",
    "    scores=cross_val_score(clf,,scoring='accuracy',cv=5)\n",
    "    print('%.3f'%(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "56\n",
      "0.544\n",
      "0.587\n",
      "0.547\n",
      "0.647\n",
      "[]\n",
      "\n",
      "Cross-Validation scores:[0.58333333 0.41666667 0.91666667 0.6        0.6       ]\n",
      "0.6233333333333333\n",
      "randomforest scores:[0.75       0.5        0.83333333 0.8        0.4       ]\n",
      "\n",
      "SVC scores:[0.75       0.58333333 0.58333333 0.8        0.6       ]\n",
      "\n",
      "Logistic scores:[0.58333333 0.75       0.75       0.5        0.6       ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#入力データとラベルを結合する\n",
    "labels=np.hstack((labels2,labels3))\n",
    "docs=np.array(docs2+docs3)\n",
    "print(len(docs))\n",
    "print(len(labels))\n",
    "\n",
    "\n",
    "\n",
    "#ベクトル化する\n",
    "vectorizer = CountVectorizer()\n",
    "X=vectorizer.fit_transform(docs)\n",
    "features = vectorizer.get_feature_names()\n",
    "# print(features)\n",
    "\n",
    "#トレーニングデータと正解データを分ける。\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(X, labels, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "models_name = [\"SVM\", \"決定木\", \"ランダムフォレスト\",\"ナイーブベイズ\"]\n",
    "models = [SVC(), DecisionTreeClassifier(), RandomForestClassifier(),MultinomialNB()]\n",
    "params = [{\"C\": [10 ** i for i in range(-5, 5)],\n",
    "           \"kernel\": [\"linear\", \"rbf\", \"poly\", \"sigmoid\"]},\n",
    "          {\"max_depth\": [i for i in range(1, 10)]},\n",
    "          {\"n_estimators\": [i for i in range(10, 20)],\n",
    "           \"max_depth\": [i for i in range(1, 10)]},\n",
    "            {\"alpha\":[i/10 for i in range(1,10)]}]\n",
    "\n",
    "best_params=[]\n",
    "for name, model, param in zip(models_name, models, params):\n",
    "    clf = GridSearchCV(model, param)\n",
    "    scores=cross_val_score(clf,train_data,train_labels,scoring='accuracy',cv=5)\n",
    "    print('%.3f'%(np.mean(scores)))\n",
    "\n",
    "print(best_params)    \n",
    "\n",
    "\n",
    "#     clf=clf.fit(train_data,train_labels)\n",
    "#     print( \"最適パラメータ：{}\".format(clf.best_params_))\n",
    "#     print( \"最良スコア：{}\".format(clf.best_score_))\n",
    "#     best_params.append(clf.best_params_)\n",
    "\n",
    "\n",
    "\n",
    "#     clf=clf.best_estimator_\n",
    "#     clf.fit(train_data,train_labels)\n",
    "#     print(clf.score(test_data,test_labels))\n",
    "\n",
    "#     scores=cross_val_score(clf,train_data,train_labels,cv=5)\n",
    "# #     print(name)\n",
    "#     print('Cross-Validation scores:{}'.format(scores))\n",
    "#     print(np.average(scores))\n",
    "#     print()\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "print()\n",
    "#ナイブベイズ\n",
    "clf = MultinomialNB()\n",
    "scores=cross_val_score(clf,X,labels,cv=5)\n",
    "print('Cross-Validation scores:{}'.format(scores))\n",
    "print(np.average(scores))\n",
    "\n",
    "#ランダムフォレスト\n",
    "clf2 = DecisionTreeClassifier(random_state=0)\n",
    "scores=cross_val_score(clf2,X,labels,cv=5)\n",
    "print('randomforest scores:{}'.format(scores))\n",
    "print()\n",
    "\n",
    "#SVM\n",
    "clf3 =SVC()\n",
    "scores=cross_val_score(clf3,X,labels,cv=5)\n",
    "print('SVC scores:{}'.format(scores))\n",
    "print()\n",
    "\n",
    "#ロジスティック回帰\n",
    "clf4 =LogisticRegression()\n",
    "scores=cross_val_score(clf4,X,labels,cv=5)\n",
    "print('Logistic scores:{}'.format(scores))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_decision_regions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f8651b1371c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# forest.fit(test_data,train_labels)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mplot_decision_regions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_combined\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_combined\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m105\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'upper left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_decision_regions' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "forest=RandomForestClassifier()\n",
    "forest=forest.fit(train_data,train_labels)\n",
    "X_combined=np.vstack((train_data,test_data))\n",
    "Y_combined=np.hstack((train_labels,test_labels))\n",
    "\n",
    "# forest.fit(test_data,train_labels)\n",
    "plot_decision_regions(X_combined,Y_combined,classifier=forest,test_idx=range(105,150))\n",
    "plt.legent(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#入力データとラベルを結合する\n",
    "labels=np.hstack((labels2,labels3))\n",
    "docs=np.array(docs2+docs3)\n",
    "\n",
    "#ベクトル化する\n",
    "vectorizer = CountVectorizer()\n",
    "X=vectorizer.fit_transform(docs)\n",
    "features = vectorizer.get_feature_names()\n",
    "# print(features)\n",
    "\n",
    "\n",
    "\n",
    "#ナイブベイズ\n",
    "clf = MultinomialNB()\n",
    "scores=cross_val_score(clf,X,labels,cv=5)\n",
    "print('Cross-Validation scores:{}'.format(scores))\n",
    "print()\n",
    "\n",
    "#ランダムフォレスト\n",
    "clf2 = DecisionTreeClassifier(random_state=0)\n",
    "scores=cross_val_score(clf2,X,labels,cv=5)\n",
    "print('randomforest scores:{}'.format(scores))\n",
    "print()\n",
    "\n",
    "#SVM\n",
    "clf3 =SVC()\n",
    "scores=cross_val_score(clf3,X,labels,cv=5)\n",
    "print('SVC scores:{}'.format(scores))\n",
    "print()\n",
    "\n",
    "#ロジスティック回帰\n",
    "clf4 =LogisticRegression()\n",
    "scores=cross_val_score(clf4,X,labels,cv=5)\n",
    "print('Logistic scores:{}'.format(scores))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.8823529411764706\n",
      "Cross-Validation scores:[0.58333333 0.41666667 0.91666667 0.6        0.6       ]\n",
      "\n",
      "randomforest scores:[0.75       0.5        0.83333333 0.8        0.4       ]\n",
      "1.0\n",
      "0.6470588235294118\n",
      "\n",
      "SVC scores:[0.75       0.58333333 0.58333333 0.8        0.6       ]\n",
      "0.7435897435897436\n",
      "0.5294117647058824\n",
      "\n",
      "Logistic scores:[0.58333333 0.75       0.75       0.5        0.6       ]\n",
      "1.0\n",
      "0.7647058823529411\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "labels=np.hstack((labels2,labels3))\n",
    "docs=np.array(docs2+docs3)\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(docs, labels, test_size=0.3, random_state=0)\n",
    "\n",
    "\n",
    "#ベクトル化する\n",
    "vectorizer = CountVectorizer()\n",
    "X=vectorizer.fit_transform(docs)\n",
    "train_matrix = vectorizer.fit_transform(train_data)\n",
    "features = vectorizer.get_feature_names()\n",
    "test_matrix = vectorizer.transform(test_data)\n",
    "\n",
    "#ナイブベイズ\n",
    "clf = MultinomialNB()\n",
    "clf.fit(train_matrix, train_labels)\n",
    "print(clf.score(train_matrix, train_labels))\n",
    "print(clf.score(test_matrix, test_labels))\n",
    "\n",
    "scores=cross_val_score(clf,X,labels,cv=5)\n",
    "print('Cross-Validation scores:{}'.format(scores))\n",
    "print()\n",
    "\n",
    "#ランダムフォレスト\n",
    "clf2 = DecisionTreeClassifier(random_state=0)\n",
    "clf2.fit(train_matrix, train_labels)\n",
    "scores=cross_val_score(clf2,X,labels,cv=5)\n",
    "print('randomforest scores:{}'.format(scores))\n",
    "print(clf2.score(train_matrix, train_labels))\n",
    "print(clf2.score(test_matrix, test_labels))\n",
    "print()\n",
    "\n",
    "#SVM\n",
    "clf3 =SVC()\n",
    "clf3.fit(train_matrix, train_labels)\n",
    "scores=cross_val_score(clf3,X,labels,cv=5)\n",
    "print('SVC scores:{}'.format(scores))\n",
    "print(clf3.score(train_matrix, train_labels))\n",
    "print(clf3.score(test_matrix, test_labels))\n",
    "print()\n",
    "\n",
    "#ロジスティック回帰\n",
    "clf4 =LogisticRegression()\n",
    "clf4.fit(train_matrix, train_labels)\n",
    "scores=cross_val_score(clf4,X,labels,cv=5)\n",
    "print('Logistic scores:{}'.format(scores))\n",
    "print(clf4.score(train_matrix, train_labels))\n",
    "print(clf4.score(test_matrix, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "これよりしたは使わない↓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "書きなぐりお試しコードである"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\Docments\\Old_yato\\old_text\\00_下村博文\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\01_下村博文\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\01_菅原一秀\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\02_谷川弥一\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\02_野田毅\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\03_谷畑孝\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\03_加藤紘一\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\04_山本幸三\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\04_町村信孝\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\05_塩崎恭久\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\05_小里泰弘\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\06_武部勤\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\06_富田茂之\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\07_金田勝年\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\07_金子一義\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\08_遠山清彦\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\08_菅義偉\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\09_小泉進次郎\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\09_田村憲久\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\10_齋藤健\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\10_谷川弥一\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\11_馳浩\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\11_谷畑孝\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\12_菅原一秀\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\12_山本幸三\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\13_石破茂\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\13_塩崎恭久\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\14_赤澤亮正\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\14_武部勤\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\15_伊東良孝\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\15_金田勝年\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\16_橘慶一郎\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\16_遠山清彦\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\17_高木陽介\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\17_小泉進次郎\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\18_東順治\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\18_齋藤健\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\19_小野寺五典\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\19_馳浩\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\20_小池百合子\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\20_石破茂\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\21_佐田玄一郎\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\21_赤澤亮正\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\22_野田毅\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\22_伊東良孝\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\23_加藤紘一\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\23_橘慶一郎\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\24_町村信孝\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\24_高木陽介\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\25_小里泰弘\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\25_東順治\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\26_富田茂之\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\26_小野寺五典\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\27_金子一義\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\27_小池百合子\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\28_菅義偉\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\28_佐田玄一郎\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\29_田村憲久\n",
      ".txt\n"
     ]
    }
   ],
   "source": [
    "import glob \n",
    "import re\n",
    "import os\n",
    "\n",
    "\n",
    "path_list=glob.glob(r'.\\Docments\\Old_yato\\old_text/*.txt')\n",
    "path_list=[re.sub('(.*)old_yato_','',path) for path in path_list]\n",
    "# print(path_list)\n",
    "\n",
    "path_list2=glob.glob('./Docments/Old_yato/old_fixed_matubi/*.txt')\n",
    "path_list2=[re.sub('(.*)old_yato_','',path) for path in path_list2]\n",
    "\n",
    "for f,f2 in zip(path_list,path_list2):\n",
    "    ftitle,fext=os.path.splitext(f)\n",
    "    print(ftitle)\n",
    "    print(fext)\n",
    "    ftitle2,fext2=os.path.splitext(f2)\n",
    "\n",
    "    print(ftitle2)\n",
    "    print(fext2)\n",
    "    \n",
    "#     os.rename(f2,ftitle+fext)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('./testdir/*')\n",
    "\n",
    "for f in files:\n",
    "    ftitle, fext = os.path.splitext(f)\n",
    "    \n",
    "#     os.rename(f, ftitle + '_img' + fext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa', ' ', 'ccc']\n",
      "aa ccc\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "copus=[]\n",
    "a=['aa']\n",
    "c=['ccc']\n",
    "\n",
    "copus.append(a[0])\n",
    "copus.append(' ')\n",
    "copus.append(c[0])\n",
    "print(copus)\n",
    "\n",
    "b=''.join(copus)\n",
    "\n",
    "print(b)\n",
    "print(type(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
