{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\icech\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:22: DeprecationWarning: generator 'make_lines2' raised StopIteration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Mecab_func import*\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "new_list=glob.glob(r'C:\\Users\\icech\\Desktop\\share\\Lab\\2018_07_04\\Docments\\New_yato\\new_matubi/*.txt')\n",
    "old_list=glob.glob(r'C:\\Users\\icech\\Desktop\\share\\Lab\\2018_07_04\\Docments\\Old_yato\\old_matubi/*.txt')\n",
    "\n",
    "\n",
    "#読点以下のMeCabファイルから、4語以下に成型して出力する関数\n",
    "def Output_matsubi_BoWList(write_file,mecab_file):\n",
    "\n",
    "    copus=[]\n",
    "    #語数カウンター\n",
    "    word=\"\"\n",
    "    for morphemes in make_lines2(mecab_file):\n",
    "        # print(morphemes)\n",
    "    #   ↑デバッグ用\n",
    "        # word_counter.update([morpheme['surface']])\n",
    "\n",
    "        if len(morphemes)>=5:\n",
    "            copus.append(morphemes[-5]+morphemes[-4]+morphemes[-3]+morphemes[-2])\n",
    "        elif len(morphemes)>=4:\n",
    "            copus.append(morphemes[-4]+morphemes[-3]+morphemes[-2])\n",
    "            # print(copus)\n",
    "            # print(3)\n",
    "        elif len(morphemes)>=3:\n",
    "            # print(morphemes)\n",
    "            copus.append(morphemes[-3]+morphemes[-2])\n",
    "            # print(copus)\n",
    "            # print(2)\n",
    "        elif len(morphemes)>=2:\n",
    "            copus.append(morphemes[-2])\n",
    "            # print(copus)\n",
    "            # print(1)\n",
    "    # print('--------------coups---------------------------')        \n",
    "    # # print(copus)\n",
    "    # print('--------------coups---------------------------')        \n",
    "\n",
    "    word=''.join(str(copus))\n",
    "    # word+=copus\n",
    "#     print('--------------word---------------------------')      \n",
    "    # print(word)\n",
    "#     print('--------------word---------------------------')\n",
    "    # return copus\n",
    "    return word      \n",
    "    # with open(write_file, mode='w',errors='ignore') as out_file:\n",
    "    #     out_file.write(word)\n",
    "\n",
    "\n",
    "docs2=[]\n",
    "path_list2=glob.glob(r'C:\\Users\\icech\\Desktop\\share\\Lab\\2018_07_04\\Docments\\New_yato\\new_matubi/*.txt')\n",
    "for i,path in enumerate(path_list2):\n",
    "    labels2=[]\n",
    "    print(i)\n",
    "    # to_mecab(path,'{}.mecab'.format(path))\n",
    "    docs2.append(Output_matsubi_BoWList('{}_fixed_new_matubi.txt'.format(i),'{}.mecab'.format(path)))\n",
    "#     print(docs2)\n",
    "    labels2=np.zeros(len(path_list2))\n",
    "\n",
    "\n",
    "docs3=[]\n",
    "path_list3=glob.glob(r'C:\\Users\\icech\\Desktop\\share\\Lab\\2018_07_04\\Docments\\Old_yato\\old_matubi/*.txt')\n",
    "for i,path in enumerate(path_list3):\n",
    "    labels3=[]\n",
    "    print(i)\n",
    "    # to_mecab(path,'{}.mecab'.format(path))\n",
    "    docs3.append(Output_matsubi_BoWList('{}_fixed_new_matubi.txt'.format(i),'{}.mecab'.format(path)))\n",
    "    labels3=np.ones(len(path_list3))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "63\n",
      "=========================================================\n",
      "=========================================================\n",
      "=========================================================\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "=========================================================\n",
      "1.0\n",
      "0.6842105263157895\n",
      "Cross-Validation scores:[0.76923077 0.61538462 0.69230769 0.76923077 0.72727273]\n",
      "\n",
      "randomforest scores:[0.61538462 0.69230769 0.53846154 0.53846154 0.45454545]\n",
      "1.0\n",
      "0.5263157894736842\n",
      "\n",
      "SVC scores:[0.53846154 0.53846154 0.53846154 0.53846154 0.54545455]\n",
      "0.7272727272727273\n",
      "0.631578947368421\n",
      "\n",
      "Logistic scores:[0.69230769 0.61538462 0.69230769 0.76923077 0.72727273]\n",
      "1.0\n",
      "0.631578947368421\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "docs=docs2+docs3\n",
    "labels=np.hstack((labels2,labels3))\n",
    "\n",
    "docs=np.array(docs)\n",
    "# labels=np.array(labels)\n",
    "\n",
    "\n",
    "print(labels)\n",
    "print(len(labels))\n",
    "print('=========================================================')\n",
    "# print(docs)\n",
    "print('=========================================================')\n",
    "\n",
    "# print(type(labels))\n",
    "# indices = list(range(len(docs)))\n",
    "# print(indices)\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(docs, labels, test_size=0.3, random_state=0)\n",
    "\n",
    "# print(test_labels)\n",
    "\n",
    "\n",
    "#ベクトル化する\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X=vectorizer.fit_transform(docs)\n",
    "\n",
    "\n",
    "\n",
    "train_matrix = vectorizer.fit_transform(train_data)\n",
    "features = vectorizer.get_feature_names()\n",
    "# print(features)\n",
    "print('=========================================================')\n",
    "\n",
    "print(type(train_matrix))\n",
    "test_matrix = vectorizer.transform(test_data)\n",
    "print('=========================================================')\n",
    "\n",
    "# print(test_matrix)\n",
    "# print(train_matrix)\n",
    "\n",
    "# print(vectorizer.vocabulary_)\n",
    "#ナイブベイズ\n",
    "clf = MultinomialNB()\n",
    "clf.fit(train_matrix, train_labels)\n",
    "print(clf.score(train_matrix, train_labels))\n",
    "print(clf.score(test_matrix, test_labels))\n",
    "\n",
    "scores=cross_val_score(clf,X,labels,cv=5)\n",
    "print('Cross-Validation scores:{}'.format(scores))\n",
    "print()\n",
    "\n",
    "#ランダムフォレスト\n",
    "clf2 = DecisionTreeClassifier(random_state=0)\n",
    "clf2.fit(train_matrix, train_labels)\n",
    "scores=cross_val_score(clf2,X,labels,cv=5)\n",
    "print('randomforest scores:{}'.format(scores))\n",
    "print(clf2.score(train_matrix, train_labels))\n",
    "print(clf2.score(test_matrix, test_labels))\n",
    "print()\n",
    "\n",
    "#SVM\n",
    "clf3 =SVC()\n",
    "clf3.fit(train_matrix, train_labels)\n",
    "scores=cross_val_score(clf3,X,labels,cv=5)\n",
    "print('SVC scores:{}'.format(scores))\n",
    "print(clf3.score(train_matrix, train_labels))\n",
    "print(clf3.score(test_matrix, test_labels))\n",
    "print()\n",
    "\n",
    "#ロジスティック回帰\n",
    "clf4 =LogisticRegression()\n",
    "clf4.fit(train_matrix, train_labels)\n",
    "scores=cross_val_score(clf4,X,labels,cv=5)\n",
    "print('Logistic scores:{}'.format(scores))\n",
    "print(clf4.score(train_matrix, train_labels))\n",
    "print(clf4.score(test_matrix, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\Docments\\Old_yato\\old_text\\00_下村博文\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\01_下村博文\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\01_菅原一秀\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\02_谷川弥一\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\02_野田毅\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\03_谷畑孝\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\03_加藤紘一\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\04_山本幸三\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\04_町村信孝\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\05_塩崎恭久\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\05_小里泰弘\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\06_武部勤\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\06_富田茂之\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\07_金田勝年\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\07_金子一義\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\08_遠山清彦\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\08_菅義偉\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\09_小泉進次郎\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\09_田村憲久\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\10_齋藤健\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\10_谷川弥一\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\11_馳浩\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\11_谷畑孝\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\12_菅原一秀\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\12_山本幸三\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\13_石破茂\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\13_塩崎恭久\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\14_赤澤亮正\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\14_武部勤\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\15_伊東良孝\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\15_金田勝年\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\16_橘慶一郎\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\16_遠山清彦\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\17_高木陽介\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\17_小泉進次郎\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\18_東順治\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\18_齋藤健\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\19_小野寺五典\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\19_馳浩\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\20_小池百合子\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\20_石破茂\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\21_佐田玄一郎\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\21_赤澤亮正\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\22_野田毅\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\22_伊東良孝\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\23_加藤紘一\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\23_橘慶一郎\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\24_町村信孝\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\24_高木陽介\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\25_小里泰弘\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\25_東順治\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\26_富田茂之\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\26_小野寺五典\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\27_金子一義\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\27_小池百合子\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\28_菅義偉\n",
      ".txt\n",
      ".\\Docments\\Old_yato\\old_text\\28_佐田玄一郎\n",
      ".txt\n",
      "./Docments/Old_yato/old_fixed_matubi\\29_田村憲久\n",
      ".txt\n"
     ]
    }
   ],
   "source": [
    "import glob \n",
    "import re\n",
    "import os\n",
    "\n",
    "\n",
    "path_list=glob.glob(r'.\\Docments\\Old_yato\\old_text/*.txt')\n",
    "path_list=[re.sub('(.*)old_yato_','',path) for path in path_list]\n",
    "# print(path_list)\n",
    "\n",
    "path_list2=glob.glob('./Docments/Old_yato/old_fixed_matubi/*.txt')\n",
    "path_list2=[re.sub('(.*)old_yato_','',path) for path in path_list2]\n",
    "\n",
    "for f,f2 in zip(path_list,path_list2):\n",
    "    ftitle,fext=os.path.splitext(f)\n",
    "    print(ftitle)\n",
    "    print(fext)\n",
    "    ftitle2,fext2=os.path.splitext(f2)\n",
    "\n",
    "    print(ftitle2)\n",
    "    print(fext2)\n",
    "    \n",
    "#     os.rename(f2,ftitle+fext)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('./testdir/*')\n",
    "\n",
    "for f in files:\n",
    "    ftitle, fext = os.path.splitext(f)\n",
    "    \n",
    "#     os.rename(f, ftitle + '_img' + fext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa', ' ', 'ccc']\n",
      "aa ccc\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "copus=[]\n",
    "a=['aa']\n",
    "c=['ccc']\n",
    "\n",
    "copus.append(a[0])\n",
    "copus.append(' ')\n",
    "copus.append(c[0])\n",
    "print(copus)\n",
    "\n",
    "b=''.join(copus)\n",
    "\n",
    "print(b)\n",
    "print(type(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
